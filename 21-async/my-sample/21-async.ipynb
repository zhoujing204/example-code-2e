{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 21: Asynchronous Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The problem with normal approaches to asynchronous programming is that they're all-or-nothing propositions. You rewrite all your code so none of it blocks or you're just wasting your time. \n",
    "> -- Alvaro Videla and Jason J. W. Williams, RabbitMQ in Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter addresses three major topics that are closely related:\n",
    "\n",
    "- Python's `async def`, `await`, `async with`, and `async for` constructs\n",
    "- Objects supporting those constructs: native coroutines and asynchronous variants of context managers, iterables, generators, and comprehensions\n",
    "- `asyncio` and other asynchronous libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Native coroutine: A coroutine function defined with `async def`. You can delegate from a native coroutine to another native coroutine using the `await` keyword, similar to how classic coroutines use `yield from`. The `async def` statement always defines a native coroutine, even if the `await` keyword is not used in its body. The `await` keyword cannot be used outside of a native coroutine.\n",
    "\n",
    "- Classic coroutine: A generator function that consumes data sent to it via `my_coro.send(data)` calls, and reads that data by using `yield` in an expression. Classic coroutines can delegate to other classic coroutines using `yield from`. Classic coroutine cannot be driven by `await`, and are no longer supported by `asyncio`.\n",
    "\n",
    "- Generator-based coroutine: A generator function decorated with `@types.coroutine` -- introduced in Python 3.5. That decorator makes the generator compatible with the new `await` keyword. It's in the process of being deprecated in favor of native coroutines.\n",
    "\n",
    "- Asynchronous generator: A generator function defined with `async def` and using `yield` in its body. It returns an asynchronous generator object that provides `__anext__`, a coroutine method to retrieve the next item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An asyncio Example: Probing Domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 21-1. blogdom.py: search for domains for a Python blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import socket\n",
    "from keyword import kwlist\n",
    "\n",
    "MAX_KEYWORD_LEN = 4 #1\n",
    "\n",
    "async def probe(domain: str) -> tuple[str, bool]: #2\n",
    "    loop = asyncio.get_running_loop() #3\n",
    "    try:\n",
    "        await loop.getaddrinfo(domain, None) #4\n",
    "    except socket.gaierror:\n",
    "        return domain, False\n",
    "    return domain, True\n",
    "\n",
    "async def main(): #5\n",
    "    names = (kw for kw in kwlist if len(kw) <= MAX_KEYWORD_LEN) #6\n",
    "    domains = (f'{name}.dev'.lower() for name in names) #7\n",
    "    coros = [probe(domain) for domain in domains] #8\n",
    "    for coro in asyncio.as_completed(coros): #9\n",
    "        domain, found = await coro  #10\n",
    "        mark = '+' if found else '-' \n",
    "        print(f'{mark} {domain}')\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    asyncio.run(main()) #11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set maximum length of keyword for domains, because shorter is better.\n",
    "\n",
    "2. `probe` returns a tuple with the domain name and a boolean; `True` means the domain resolved. Return the domain name will make it easier to display the results.\n",
    "\n",
    "3. Get a reference to the `asyncio` event loop, so we can use it next.\n",
    "\n",
    "4. The `loop.getaddrinfo()` coroutine-method returns a five-part tuple of parameters to connect to the given address using a socket. In this example, we don't need the result. If we got it, the domain resolves; otherwise, it doesn't.\n",
    "\n",
    "5. `main` must be a coroutine, so that we can use `await` in it.\n",
    "\n",
    "6. Generator to yield Python keywords with length to `MAX_KEYWORD_LEN`.\n",
    "\n",
    "7. Generator to yield domains with the `.dev` suffix.\n",
    "\n",
    "8. Build a list of coroutine objects by invoking the `probe` coroutine with each `domain` argument.\n",
    "\n",
    "9. `asyncio.as_completed` is generator that yields coroutines that return the results of the coroutines passed to it in the order they are completed--not the order they were submitted. It's similar to `future.as_completed` in the previous chapter.\n",
    "\n",
    "10. At this point, we know the coroutines is done because that's how `as_completed` works. Therefore, the `await` expression will not block but we need it to get the result from `coro`. If `coro` raised an unhandled exception, it would be re-raised here.\n",
    "\n",
    "11. `asyncio.run` starts the event loop and return only when the event loop exits. This is a common pattern for scripts that use `asyncio`: implement `main` as a coroutine, and drive it with `asyncio.run` inside the `if __name__ == __main__:` block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guido's Trick to Read Async Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A trick suggested by Guido van Rossum himself: squint and pretend `async` and `await` keywords are not there. If you do that, you'll realize that coroutines read like plain old sequential functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Concept: Awaitable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `await` keyword works with `awaitables`. As an end user of `asyncio`, these are the awaitables you'll encounter:\n",
    "\n",
    "-  A `native coroutine object`, which you get by calling a `native coroutine function`.\n",
    "\n",
    "- An `asyncio.Task`, which you usually get by passing a coroutine object to `asyncio.create_task()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading with asyncio and HTTPX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 21-3. flags_asyncio.py: imports and download functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from httpx import AsyncClient #1\n",
    "from flags import BASE_URL, save_flag, main #2\n",
    "\n",
    "async def download_one(client: AsyncClient, cc: str): #3\n",
    "    image = await get_flag(client, cc) \n",
    "    save_flag(image, f'{cc}.gif')\n",
    "    print(cc, end=' ', flush=True)\n",
    "    return cc\n",
    "\n",
    "\n",
    "async def get_flag(client: AsyncClient, cc: str) -> bytes: #4\n",
    "    url = f'{BASE_URL}/{cc}/{cc}.gif'.lower() \n",
    "    resp = await client.get(url, timeout=6.1,\n",
    "                            follow_redirects=True) #5\n",
    "    return resp.read() #6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `httpx` must be installed--it's not part of the standard library.\n",
    "\n",
    "2. Reuse code from `flags.py`.\n",
    "\n",
    "3. `download_one` must be a native coroutine, so it can `await` on `get_flag`--which does the `HTTP` request. Then it displays the code of the downloaded flag, and saves the image.\n",
    "\n",
    "4. `get_flag` needs to receive the `AsyncClient` to make the request.\n",
    "\n",
    "5. The `get` method of an `httpx.AsyncClient` instance returns a `ClientResponse` object that is also an asynchronous context manager.\n",
    "\n",
    "6. Network I/O operations are implemented as coroutine methods, so they are driven by the `asyncio` event loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 21-2. flags_asynico.py: startup functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_many(cc_list: list[str]) -> int: #1\n",
    "    return asyncio.run(supervisor(cc_list)) #2\n",
    "\n",
    "async def supervisor(cc_list: list[str]) -> int: \n",
    "    async with AsyncClient() as client: #3\n",
    "        to_do = [download_one(client, cc) \n",
    "                    for cc in sorted(cc_list)] #4\n",
    "        res = await asyncio.gather(*to_do) #5\n",
    "    return len(res) #6\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main(download_many) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This needs to be a plain function--not a coroutine--so it can be passed to and called by the `main` function from the `main` function.\n",
    "\n",
    "2. Execute the event loop driving the `supervisor(cc_list)` coroutine object until it returns. This will block while the event loop runs. The result of this line is whatever the `supervisor` coroutine returns.\n",
    "\n",
    "3. `Asynchronous` HTTP client operations in `httpx` are methods of `AsyncClient`, which is also an asynchronous context manager: a context manager with asynchronous setup and teardown methods.\n",
    "\n",
    "4. Build a list of coroutine objects by calling the `download_one` coroutine once for each flag to be retrieved.\n",
    "\n",
    "5. Wait for the `asyncio.gather` coroutine, which accepts one or more awaitable arguments and waits for them to complete, returning a list of results for the given awaitables in the order they were submitted.\n",
    "\n",
    "6. `supervisor` returns the length of the list returned by `asyncio.gather`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "asyncio.as_completed方法和asyncio.gather方法是Python asyncio库中用于并发执行协程的两种常用方法。它们在处理并发任务时有一些区别和特点。\n",
    "\n",
    "1. asyncio.as_completed方法：\n",
    "   - asyncio.as_completed方法接受一个协程列表作为参数，并返回一个可迭代对象。\n",
    "   - 通过使用await关键字，可以逐个获取已完成的协程的结果。\n",
    "   - 当有协程完成时，as_completed方法会立即返回该协程的结果，而不需要等待其他协程完成。\n",
    "   - 这种方法适用于需要按照完成顺序逐个处理结果的情况。\n",
    "\n",
    "2. asyncio.gather方法：\n",
    "   - asyncio.gather方法接受一个或多个协程作为参数，并返回一个新的协程。\n",
    "   - 通过使用await关键字，可以获取所有协程的结果。\n",
    "   - gather方法会等待所有协程都完成后才返回结果，即所有协程都执行完毕后才会继续执行后续代码。\n",
    "   - 这种方法适用于需要同时处理多个协程结果的情况。\n",
    "\n",
    "总结：\n",
    "- asyncio.as_completed方法适用于需要按照完成顺序逐个处理结果的情况，而asyncio.gather方法适用于需要同时处理多个协程结果的情况。\n",
    "- asyncio.as_completed方法可以在协程完成时立即获取结果，而asyncio.gather方法需要等待所有协程完成后才返回结果。\n",
    "- 根据具体需求选择合适的方法可以更好地处理并发任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Secret of Native Coroutine: Humble Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![asyncio event loop](./img/2023-11-24-14-33-22.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key difference between the classic coroutine and native coroutine is that there are no visible `.send()` calls or `yield` expressions in the latter. This is illustrated in Figure 21-1.\n",
    "\n",
    "Under the hood, the `asyncio` event loop makes the `.send()` calls that drive your coroutines, and your coroutines `await` on other coroutines, including library coroutines. As mentioned, `await` borrows most of implementation from `yield from`, which also makes `.send` calls to drive coroutines.\n",
    "\n",
    "The `await` chain eventually reaches a low-level awaitable, which returns a generator that the event loop can drive in response to events such as timers or network I/O. The low-level awaitables and generators at the end of these `await` chains are implemented into the libraries, are not part of their APIs, and maybe Python/C extensions.\n",
    "\n",
    "Using functions like `asyncio.gather` and `asyncio.created_task`, you can start multiple concurrent `await` channels, enabling concurrent execution of multiple I/O operations driven by a single event loop, in a single thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The All-or-Nothing Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For peak performance with `asyncio`, we must replace every function that does I/O with an asynchronous with `asyncio`, we must replace every function that does I/O with an asynchronous version that is activated with `await` or `asyncio.create_task`, so that control is given back to the event loop while the function waits for I/O. If you can't rewrite a blocking function as a coroutine, you should run it in a separate thread or process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can you run a thread or process in a coroutine?\n",
    "\n",
    "Short answer: use `ThreadPoolExecutor` and `as_completed` in `concurrent.futures` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous Context Managers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 21-4. Sample code from documentation of the asyncpg PostgreSQL driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "tr = connection.transaction()\n",
    "\n",
    "await tr.start()\n",
    "try:\n",
    "    await connection.execute()\n",
    "except:\n",
    "    await tr.rollback()\n",
    "    raise\n",
    "else:\n",
    "    await tr.commit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A database transaction is a natural fit for the context manager protocol: the transaction has to be started, data is changed with `connection.execute`, and then a rollback or commit must happen, depending on the outcome of the operation.\n",
    "\n",
    "In an asynchronous driver like `asyncpg`, the setup and wrap-up need to be coroutines so that other operations can happen concurrently. However, the implementation of the classic `with` statement doesn't support coroutines doing the work of `__enter__` and `__exit__`. \n",
    "\n",
    "That's why PEP 492--Coroutines with async and await syntax introduced the `async with` statement, which works with asynchronous context manager: objects implementing the `__aenter__` and `__aexit__` methods as coroutines.\n",
    "\n",
    "With `async with`, Example 21-4 can be written like this other snippet from the `asyncpg` documentation:\n",
    "\n",
    "```python\n",
    "async with connection.transaction():\n",
    "    await connection.execute(\"INSERT INTO mytable VALUES (1, 2, 3)\")\n",
    "```\n",
    "\n",
    "In the `asyncpg.Transaction class`, the `__aenter__` coroutine method does `await self.start()`, and `__aexit__` does `await self.commit()` or `await self.rollback()` depending on whether an exception was raised in the `async with` block. Using coroutines to implement `Transaction` as an asynchronous context manager allows `asyncpg` to handle many transactions concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhancing the asyncio downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using asyncio.as_completed and a Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 21-6. flags2_asyncio.py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from collections import Counter\n",
    "from http import HTTPStatus\n",
    "from pathlib import Path\n",
    "\n",
    "import httpx\n",
    "import tqdm\n",
    "\n",
    "from flags2_common import main, save_flag, DownloadStatus\n",
    "\n",
    "# low concurrency default to avoid errors from remote site,\n",
    "# such as 503 - Service Temporarily Unavailable\n",
    "\n",
    "DEFAULT_CONCUR_REQ = 5 \n",
    "MAX_CONCUR_REQ = 1000 \n",
    "\n",
    "async def get_flag(client: httpx.AsyncClient, #1\n",
    "                    cc: str,\n",
    "                    base_url: str) -> bytes:\n",
    "    url = f'{base_url}/{cc}/{cc}.gif'.lower()\n",
    "    resp = await client.get(url, timeout=6.1,\n",
    "                            follow_redirects=True) #2\n",
    "    resp.raise_for_status()\n",
    "    return resp.read()\n",
    "\n",
    "async def download_one(client: httpx.AsyncClient,\n",
    "                        cc: str,\n",
    "                        base_url: str,\n",
    "                        semahore: asyncio.Semaphore,\n",
    "                        verbose: bool) -> DownloadStatus:\n",
    "    try:\n",
    "        async with semahore: #3\n",
    "            image = await get_flag(client, cc, base_url)\n",
    "    except httpx.HTTPStatusError as exc: #4\n",
    "        res = exc.response\n",
    "        if res.status_code != 404:\n",
    "            raise\n",
    "        status = DownloadStatus.not_found\n",
    "        msg = f'not found: {res.url}'\n",
    "    else:\n",
    "        await asyncio.to_thread(save_flag, image, f'{cc}.gif') #5\n",
    "        status = DownloadStatus.ok\n",
    "        msg = 'OK'\n",
    "    if verbose and msg:\n",
    "        print(cc, msg)\n",
    "    return status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `get_flag` is very similar to the sequential version in Example 20-14. First difference: it requires the `client` parameter.\n",
    "\n",
    "2. Second and third differences: `.get` is an `AsyncClient` method, and it's a coroutine, so we need to await it.\n",
    "\n",
    "3. Use the `semaphore` as an asynchronous context manager so that the program as a whole is not blocked; only this coroutine is suspended when the semaphore counter is zero. \n",
    "\n",
    "4. The error handling logic is the same as in `download_one`.\n",
    "\n",
    "5. Saving the image is an I/O operation. To avoid blocking the event loop, run `save_flag` in a thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Throttling Requests with a Semaphore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network clients like the ones we are studying should be throttled(i.e. limited) to avoid pounding the server with too many concurrent requests.\n",
    "\n",
    "A semaphore is a synchronization primitive, more flexible that a lock. A semaphore can be held by multiple coroutines, with a configurable maximum number. This makes it ideal to throttle the number of active concurrent coroutines.\n",
    "\n",
    "In `flags2_threadpool.py` Example 20-16, the throttling was done by instantiating the `ThreadPoolExecutor` with the required `max_workers` argument set to `concur_req` in the `download_many` function. In `flag2_asyncio.py`, an `asyncio.Semaphore` is created by the supervisor function and passed as the `semaphore` argument to `download_one`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python's Semaphores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computer scientist Edsger W.Dijkstra invented the `semaphore` in the early 1960s. It's a simple idea, but it's so flexible that most other synchronization objects--such as locks and barriers--can be built on top of semaphores. There are three Semaphore classes in Python's standard library: one in threading, another in multiprocessing, and a third one in `asyncio`. Here we'll describe the latter.\n",
    "\n",
    "An `asyncio.Semaphore` has an internal counter that is decremented whenever we `await` on the `.acquire()` coroutine method, and incremented when we call the `.release()` method--which is not a coroutine because it never blocks. The initial value of the counter is set when the `Semaphore` is instantiated:\n",
    "\n",
    "```python\n",
    "semaphore = asyncio.Semaphore(concur_req)\n",
    "```\n",
    "\n",
    "Awaiting on `.acquire()` causes no delay when the counter is greater than zero, but if the counter is zero, `.acquire()` suspends the awaiting coroutine until some other coroutine calls `.release()` on the same `Semaphore`, thus incrementing the counter. Instead of using those methods directly, it's safer to use the `semaphore` as an asynchronous context manager:\n",
    "\n",
    "```python\n",
    "async with semaphore:\n",
    "    image = await get_flag(client, base_url, cc)\n",
    "```\n",
    "\n",
    "The `Semaphore.__aenter__` coroutine method await for `.acquire()`, and its `__aexit__` coroutine method calls `.release()`. That snippet guarantees that no more than `concur_req` instances of `get_flags` coroutines will be active at any time.\n",
    "\n",
    "Each of the `Semaphore` classes in the standard library has a `BoundedSemaphore` subclass that enforces an additional constraints: the internal counter can never become larger than the initial value when there are more `.release()` than `.acquire()` operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 21-7. flags2_asyncio.py: script continued from Example 21-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def supervisor(cc_list: list[str],\n",
    "                        base_url: str,\n",
    "                        verbose: bool,\n",
    "                        concur_seq: int) -> Counter[DownloadStatus]: #1\n",
    "    counter: Counter[DownloadStatus] =  Counter()\n",
    "    semaphore = asyncio.Semaphore(concur_seq) #2\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        to_do = [download_one(client, cc, base_url, semaphore, verbose)\n",
    "                    for cc in sorted(cc_list)] #3\n",
    "        to_do_iter = asyncio.as_completed(to_do) #4\n",
    "        if not verbose:\n",
    "            to_do_iter = tqdm.tqdm(to_do_iter, total=len(cc_list)) #5\n",
    "        error: httpx.HTTPError | None = None #6\n",
    "        for coro in to_do_iter: #7\n",
    "            try:\n",
    "                status = await coro #8\n",
    "            except httpx.HTTPStatusError as exc:\n",
    "                error_msg = 'HTTP error {resp.status_code} - {resp.reason_phrase}'\n",
    "                error_msg = error_msg.format(resp=exc.response)\n",
    "                error = exc #9\n",
    "            except httpx.RequestError as exc:\n",
    "                error_msg = f'{exc} {type(exc)}'.strip()\n",
    "                error = exc #10\n",
    "            except KeyboardInterrupt:\n",
    "                break\n",
    "            \n",
    "            if error:\n",
    "                status = DownloadStatus.ERROR #11\n",
    "                if verbose:\n",
    "                    url = str(error.request.url) #12\n",
    "                    cc = Path(url).stem.upper() #13\n",
    "                    print(f'{cc} error: {error_msg}')\n",
    "            counter[status] += 1\n",
    "    return counter\n",
    "\n",
    "\n",
    "def download_many(cc_list: list[str],\n",
    "                    base_url: str,\n",
    "                    verbose: bool,\n",
    "                    concur_req: int) -> Counter[DownloadStatus]:\n",
    "    coro = supervisor(cc_list, base_url, verbose, concur_req)\n",
    "    return asyncio.run(coro) #14\n",
    "                \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many, DEFAULT_CONCUR_REQ, MAX_CONCUR_REQ)        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `supervisor` takes the same arguments as the `download_many` function, but it can not be invoked directly from `main` because it's a coroutine and not a plain function like `download_many`.\n",
    "\n",
    "2. Create an `asyncio.Semaphore` that will be used to throttle the number of concurrent downloads. The value of `concur_req` is computed by the `main` function based on command-line arguments and constants set in each example.\n",
    "\n",
    "3. Create a list of coroutine objects, one per call to the `download_one` coroutine.\n",
    "\n",
    "4. Get an iterator that will return coroutine objects as they are done. I did not place this call to `as_completed` directly in the `for` loop because I may need to warp it with the `tqdm` iterator for the progress bar, depending on the user's choice for verbosity.\n",
    "\n",
    "5. Wrap the `as_completed` iterator with the `tqdm` generator function to display progress.\n",
    "\n",
    "6. Declare and initialize `error` with `None`; this variable will be used to hold an exception beyond the `try/except` statement, if one is raised.\n",
    "\n",
    "7. Iterate over the completed coroutine objects; this loop is similar to the one in `download_many` in Example 20-16.\n",
    "\n",
    "8. `await` on the coroutine to get its result. This will not block because `as_completed` only produces coroutines that are done.\n",
    "\n",
    "9. This assignment is necessary because the `exc` variable scope is limited to this except clause, but I need to preserve its value for latter.\n",
    "\n",
    "10. Same as before.\n",
    "\n",
    "11. If there was an error, set the `status`.\n",
    "\n",
    "12. In verbose mode, extract the URL from the exception that was raised...\n",
    "\n",
    "13. ...and extract the name of the file to display the country code next.\n",
    "\n",
    "14. `download_many` instantiates the `supervisor` coroutine object and passes it to the event loop with `asyncio.run`, collecting the counter `supervisor` returns when the event loop ends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Multiple Requests for Each Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 21-8. flags_asyncio.py: get_country coroutine\n",
    "\n",
    "async def get_country(client: httpx.AsyncClient,\n",
    "                    base_url: str,\n",
    "                    cc: str) -> bytes: #1\n",
    "    url = f'{base_url}/{cc}/metadata.json'.lower()\n",
    "    resp = await client.get(url, timeout=3.1,\n",
    "                            follow_redirects=True)\n",
    "    resp.raise_for_status()\n",
    "    metadata = resp.json() #2\n",
    "    return metadata['country'] #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This coroutine returns a string with the country name--if all goes well.\n",
    "\n",
    "2. `metadata` will get a Python `dict` built from the JSON contents of the response.\n",
    "\n",
    "3. Return the country name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 21-9. flags_asyncio.py: download_one coroutine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_one(client: httpx.AsyncClient,\n",
    "                        cc: str,\n",
    "                        base_url: str,\n",
    "                        semaphore: asyncio.Semaphore,\n",
    "                        verbose: bool) -> DownloadStatus:\n",
    "    try:        \n",
    "        async with semaphore:\n",
    "            image = await get_flag(client, cc, base_url) #1\n",
    "        async with semaphore:\n",
    "            country = await get_country(client, base_url, cc) #2\n",
    "    except httpx.HTTPStatusError as exc:\n",
    "        res = exc.response\n",
    "        if res.status_code == 404:\n",
    "            status = DownloadStatus.NOT_FOUND\n",
    "            msg = f'not found: {res.url}'\n",
    "        else:\n",
    "            raise\n",
    "    else:\n",
    "        filename = country.replace(' ', '_') #3\n",
    "        await asyncio.to_thread(save_flag, image, f'{filename}.gif')\n",
    "        status = DownloadStatus.OK\n",
    "        msg = 'OK'\n",
    "    if verbose and msg:\n",
    "        print(cc, msg)\n",
    "    return status \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Hold the `semaphore` to `await` for `get_flag`...\n",
    "\n",
    "2. ...and again for `get_country`\n",
    "\n",
    "3. Use the country name to create a filename. As a command-line user, I don't to see spaces in filenames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why use two semaphores here? How about one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Put the calls to `get_flag` and `get_country` in separate `with` blocks controlled by the `semaphore` because it's good practice to hold semaphores and locks for the shortest possible time.\n",
    "\n",
    "- Put the calls to `get_flag` and `get_country` in one `with` block can cause RuntimeError: 'RuntimeError: Cannot send a request, as the client has been closed.'\n",
    "\n",
    "- The second `with` block will execute after the first `with` block finish all tasks.\n",
    "\n",
    "- Put two calls of `client` in one semaphore could possible cause `client` error: `client` could not be called before it is closed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One challenge is to know when you have to use `await` and when you can't use it. The answer in principle is easy: you `await` coroutines and other awaitables, such as `asyncio.Task` instances. But some APIs are tricky, mixing coroutines and plain functions in seemingly arbitrary ways, like the `StreamWriter` class we'll use in Example-14."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delegating Tasks to Executors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python 3.9, you can use `asyncio.to_thread`:\n",
    "\n",
    "```python\n",
    "await asyncio.to_thread(save_flag, image, filename)\n",
    "```\n",
    "\n",
    "If you need to support Python 3.7 and 3.8, you can use `run_in_executor`:\n",
    "\n",
    "```python\n",
    "loop = asyncio.get_event_loop() #1\n",
    "loop.run_in_executor(None, save_flag, #2\n",
    "                        image, filename) #3\n",
    "```\n",
    "\n",
    "1. Get a reference to the event loop.\n",
    "\n",
    "2. The first argument is the executor to use; passing `None` selects the default `ThreadPoolExecutor` that is always available in `asyncio` event loop.\n",
    "\n",
    "3. You can pass positional arguments to the function to run, but if you need to pass keyword arguments, then you need to resort to `functool.partial`, as described in [documentation](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.loop.run_in_executor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing asyncio Servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll build slightly more interesting toys: server-side Unicode character search utilities, first using HTTP with `FastAPI`, then using plain TCP with `asyncio` only.\n",
    "\n",
    "![search results for \"mountain\".](./img/2023-11-27-11-57-57.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meet the Inverted Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An inverted index usually maps words to documents in which they occur. In the `mojifinder` examples, each “document” is one Unicode character. The `charindex.InvertedIndex` class indexes each word that appears in each character name in the Unicode database, and creates an inverted index stored in a `defaultdict` . For example, to index character U+0037—DIGIT SEVEN--the InvertedIndex initializer appends the character '7' to the entries under the keys 'DIGIT' and 'SEVEN'. \n",
    "\n",
    "![A demonstration using the entries for 'CAT' and 'FACE'](./img/2023-11-27-12-10-02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A FastAPI Web Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`web_mojifinder.py` is a example  of the Python ASGI(Asynchronous Server Gateway Interface) Web frameworks. It's a super simple SPA(Single Page Application): after the initial HTML download, the UI is updated by client-side JavaScript communicating with the server.\n",
    "\n",
    "`FastAPI` is designed to implement backends for SPA and mobile apps, which mostly consist of web API end points returning JSON responses instead of server-rendered HTML. `FastAPI` leverages decorators, type hints, and code introspection to eliminate a lot of the boilerplate code for web APIs, and also automatically publishes interactive OpenAPI--a.k.a. `Swagger`--documentation for the API.\n",
    "\n",
    "To run `web_mojifinder.py`, you need to install `FastAPI` and `uvicorn`. This is the command to run the server:\n",
    "\n",
    "```shell\n",
    "uvicorn web_mojifinder:app --reload\n",
    "```\n",
    "\n",
    "The parameters are:\n",
    "\n",
    "- `web_mojifinder:app`: the package name, a colon, and the name of the ASGI application defined in ti--`app` is conventional name.\n",
    "\n",
    "- `--reload`: Make `uvicorn` monitor changes to application source files and automatically reload them. Useful only during development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 21-11. web_mojifinder.py: complete source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from unicodedata import name\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from fastapi.responses import HTMLResponse\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from charindex import InvertedIndex\n",
    "\n",
    "STATIC_PATH = Path(__file__).parent / 'static'  #1\n",
    "\n",
    "app = FastAPI(  #2\n",
    "    title='MojiFinder Web',\n",
    "    description='Search for Unicode characters by name'\n",
    ")\n",
    "\n",
    "class CharName(BaseModel): #3\n",
    "    char: str\n",
    "    name: str\n",
    "    \n",
    "def init(app): #4\n",
    "    app.state.index = InvertedIndex()\n",
    "    app.state.form = (STATIC_PATH / 'form.html').read_text()\n",
    "    \n",
    "init(app)   #5\n",
    "\n",
    "@app.get('/search', response_model=list[CharName]) #6\n",
    "async def search(q: str): #7\n",
    "    chars = sorted(app.state.index.find(q))\n",
    "    return ({'char': c, 'name': name(c) } for c in chars) #8\n",
    "\n",
    "@app.get('/', response_class=HTMLResponse, include_in_schema=False) \n",
    "def form(): #9\n",
    "    return app.state.form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Unrelated to the theme of this chapter, but worth nothing: the elegant use of the overloaded/operator by `pathlib`.\n",
    "\n",
    "2. This line defines the ASGI app. It could be as simple as `app = FastAPI()`. The parameters shown are metadata for the autogenerated documentation.\n",
    "\n",
    "3. A `pydantic` schema for a JSON response with `char` and `name` fields.\n",
    "\n",
    "4. Build the `index` and load the static HTML form, attaching both to the `app.state` for later use.\n",
    "\n",
    "5. Run `init` when this module is loaded by the ASGI server.\n",
    "\n",
    "6. Route for the `/search` endpoint; `response_model` uses that `CharName` pydantic model to describe the response format.\n",
    "\n",
    "7. `FastAPI` assumes that any parameters that appear in the function or coroutine signature that are not in the route path will be passed in the HTTP query string, e.g., `/search?q=cat`. Since `q` has no default, `FastAPI` will return a 422(Unprocessable Entity) status if the query string is missing.\n",
    "\n",
    "8. Returning an iterable of `dicts` compatible with the `response_model` schema allows `FastAPI` to build the JSON response according to the `response_model` in the @app.get decorator.\n",
    "\n",
    "9. Regular functions(i.e., non-async) can also be used to produce response.\n",
    "\n",
    "10. This module has no main function. It is loaded and driven by the ASGI server--uvicorn in this case.\n",
    "\n",
    "It is a critical advantage of `FastAPI`--and ASGI frameworks in general--to support coroutines that can take advantage of asynchronous libraries for network I/O."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best practice is to have a proxy/load-balancer in front of the ASGI server to handle all static assets, and also use a CDN(Content Delivery Network) when possible. One such proxy/load-balancer is `Traefik`, a self-described \"edge router\" that \"receives requests on behalf of your system and finds out which components are responsible for handling them.\" `FastAPI` has project generation scripts that prepare your code to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Response Model in FastAPI?\n",
    "\n",
    "The response model is declared in this parameter instead of as a function return type annotation, because the path function may not actually return that response model but rather return a dict, database object or some other model, and then use the `response_model` to perform the field limiting and serialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An asyncio TCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tcp_mojifinder.py` program uses plain TCP to communicate with a client like Telnet or Netcat.\n",
    "\n",
    "![Telnet session with the tcp_mojifinder.py server](./img/2023-11-28-11-01-43.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 21-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import sys\n",
    "\n",
    "async def supervisor(index: InvertedIndex, host: str, port: int) -> None:\n",
    "    server = await asyncio.start_server( #1\n",
    "        functools.partial(finder, index), #2\n",
    "        host, port) #3\n",
    "    \n",
    "    socket_list = cast(tuple[TransportSocket, ...], server.sockets) #4\n",
    "    addr = socket_list[0].getsockname()\n",
    "    print(f'Serving on {addr}. Hit CTRL-C to stop.') #5\n",
    "    await server.serve_forever() #6\n",
    "\n",
    "def main(host: str = '127.0.0.1', port_arg: str = '2323'):\n",
    "    port = int(port_arg)\n",
    "    print('Building index...')\n",
    "    index = InvertedIndex() #7\n",
    "    try:\n",
    "        asyncio.run(supervisor(index, host, port)) #8\n",
    "    except KeyboardInterrupt:\n",
    "        print('\\nServer shut down.') #9\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main(*sys.argv[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This `await` quickly gets an instance of `asyncio.Server`, a TCP socket server. By default, `start_server` creates and starts the server, so it's ready to receive connections.\n",
    "\n",
    "2. The first argument to `start_sever` is `client_connected_cb`, a callback to run when a new client connect starts. The callback can be a function or a coroutine, but it must accept exactly two arguments: an `asyncio.StreamReader` and an `asyncio.StreamWriter`. However, my `finder` coroutine also needs to get an `index`, so I used `functools.partial` to bind that parameter and obtain a callable that takes the reader and writer. Adapting user functions to callback APIs is the most common use case for `functools.partial`.\n",
    "\n",
    "3. `host` and `port` are the second and third arguments to `start_server`. See the full signature in the `asyncio` documentation.\n",
    "\n",
    "4. This `cast` is needed because `typeshed` has an outdated type hint for `sockets` property of the `Server` class--as of May 2021. See Issue # 5535 on typeshed.\n",
    "\n",
    "5. Display the address and port of the first socket of the server.\n",
    "\n",
    "6. Although `start_server` already started the server as a concurrent task, I need to `await` on the `server_forever` method so that my `supervisor` is suspended here. Without this line, `supervisor` would return immediately, ending the loop started with `asyncio.run(supervisor(...))`, and exiting the program. The documentation for `Server.serve_forever` says: \"This method can be called if the server is already accepting connections.\"\n",
    "\n",
    "7. Build the inverted index.\n",
    "\n",
    "8. Start the event loop running `supervisor`.\n",
    "\n",
    "9. Catch the `keyboardInterrupt` to avoid a distracting traceback when I stop the server with Ctrl-C on the terminal running it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 21-14. tcp_mojifinder.py: continued from 21-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import functools\n",
    "import sys\n",
    "from asyncio.trsock import TransportSocket\n",
    "from typing import cast\n",
    "\n",
    "CRLF = b'\\r\\n'\n",
    "PROMPT = b'?> '\n",
    "\n",
    "async def finder(index: InvertedIndex, #2\n",
    "                reader: asyncio.StreamReader,\n",
    "                writer: asyncio.StreamWriter) -> None:\n",
    "    client = writer.get_extra_info('peername') #3\n",
    "    \n",
    "    while True: #4\n",
    "        writer.write(PROMPT) # can't wait #5\n",
    "        await writer.drain() # must wait #6\n",
    "        data = await reader.readline() #7\n",
    "        if not data: #8\n",
    "            break\n",
    "        try:\n",
    "            query = data.decode().strip()  #9\n",
    "        except UnicodeDecodeError: #10\n",
    "            query = '\\x00'\n",
    "        print(f' From  {client}: {query!r}') #11\n",
    "        if query:\n",
    "            if ord(query[:1]) < 32: #12\n",
    "                break\n",
    "            results = await search(query, index, writer) #13\n",
    "            print(f'    To {client}: {results} results.') #14\n",
    "        writer.close() #15\n",
    "        await writer.wait_closed() #16\n",
    "        print(f'Close {client}.') #17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StreamWriter.write` is a plain function, because it writes to a buffer.\n",
    "\n",
    "On the other hand, `StreamWriter.drain`--which flushes the buffer and performs the network I/O--is a coroutine, as is `StreamReader.readline`--but not `StreamWriter.writelines`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous Iteration and Asynchronous Iterables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`async` for works with asynchronous iterables: objects that implement `__aiter__`. However, `__aiter__` must be a regular method--not a coroutine method--and it must return an asynchronous iterator.\n",
    "\n",
    "An asynchronous iterator provides an `__anext__` coroutine method that returns an awaitable--often a coroutine object. They are also expected to implement `__aiter__`, which usually returns `self`. This mirrors the important distinction of iterables and iterators we discussed in \"Don't Make the Iterable an Iterator for Itself\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous generators versus native coroutines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Both are declared with `async def`.\n",
    "\n",
    "- An asynchronous generator always has a `yield` expression in its body--that's what makes it a generator. A native coroutine never contains `yield`.\n",
    "\n",
    "- A native coroutine may return some value other than `None`. An asynchronous generator can only use empty `return` statements.\n",
    "\n",
    "- Native coroutines are awaitable. Asynchronous generators are not awaitable. They are asynchronous iterables, driven by `async for` or asynchronous comprehensions.\n",
    "\n",
    "- An asynchronous generator expression can be defined anywhere in your program, but it can only be consumed inside a native coroutine or asynchronous generator function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## async Beyond asyncio: Curio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type Hinting Asynchronous Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Async Works and How It doesn't"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
