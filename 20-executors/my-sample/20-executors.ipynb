{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 20: Concurrent Executors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Sequential Download Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "import httpx  # <1>\n",
    "\n",
    "POP20_CC = ('CN IN US ID BR PK NG BD RU JP '\n",
    "            'MX PH VN ET EG DE IR TR CD FR').split()  # <2>\n",
    "\n",
    "BASE_URL = 'https://www.fluentpython.com/data/flags'  # <3>\n",
    "DEST_DIR = Path('downloaded')                         # <4>\n",
    "\n",
    "def save_flag(img: bytes, filename: str) -> None:     # <5>\n",
    "    (DEST_DIR / filename).write_bytes(img)\n",
    "\n",
    "def get_flag(cc: str) -> bytes:  # <6>\n",
    "    url = f'{BASE_URL}/{cc}/{cc}.gif'.lower()\n",
    "    resp = httpx.get(url, timeout=6.1,       # <7>\n",
    "                    follow_redirects=True)   # <8>\n",
    "    resp.raise_for_status()  # <9>\n",
    "    return resp.content\n",
    "\n",
    "\n",
    "def download_many(cc_list: list[str]) -> int:  # <10>\n",
    "    for cc in sorted(cc_list):                 # <11>\n",
    "        image = get_flag(cc)\n",
    "        save_flag(image, f'{cc}.gif')\n",
    "        print(cc, end=' ', flush=True)         # <12>\n",
    "    return len(cc_list)\n",
    "\n",
    "def main(downloader: Callable[[list[str]], int]) -> None:  # <13>\n",
    "    DEST_DIR.mkdir(exist_ok=True)                          # <14>\n",
    "    t0 = time.perf_counter()                               # <15>\n",
    "    count = downloader(POP20_CC)\n",
    "    elapsed = time.perf_counter() - t0\n",
    "    print(f'\\n{count} downloads in {elapsed:.2f}s')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many)     # <16>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `httpx` library. It's not part of the standard library, so by convention the import goes after the standard library imports and a blank line.\n",
    "\n",
    "2. List of the ISO 3166 country codes for the most populous countries in order of descending population. The list is from [Wikipedia](https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population).\n",
    "\n",
    "3. The directory with the flag images. \n",
    "\n",
    "4. Local directory where the images are saved. \n",
    "\n",
    "5. Save the `img` bytes to `filename` in the `DEST_DIR` directory.\n",
    "\n",
    "6. Given a country code, build the URL and download the image, returning the binary contents of the response.\n",
    "\n",
    "7. It's good practice to add a sensible timeout to network operations, to avoid blocking for several minutes for no good reason.\n",
    "\n",
    "8. By default, HTTPX does not follow redirects.\n",
    "\n",
    "9. There's no error handling in this script, but this method raises an exception if the HTTP status is not in the 2XX range--highly recommended to avoid silent failures.\n",
    "\n",
    "10. `download_many` is the key function to compare with the concurrent implementations.\n",
    "\n",
    "11. Loop over the list of country codes in alphabetical order, to make it easy to see that the ordering is preserved in the output; return the number of country codes downloaded.\n",
    "\n",
    "12. Display one country code at a time in the same line so we can see progress as each download happens. The end=' ' argument replaces the usual line break at the end of each line with a space, so the next print call will continue on the same line. The `flush=True` argument is needed to ensure that the output is displayed immediately, by default, Python is line buffered, meaning that Python only displays printed characters when it sees a line break or when the buffer is full.\n",
    "\n",
    "13. `main` must be called with the function that will make the downloads; that way, we can use `main` as library function with other implementations of `download_many` in the future.\n",
    "\n",
    "14. Create `DEST_DIR` if it doesn't exist, don't raise an exception if it already exists.\n",
    "\n",
    "15. Record and report the elapsed time after running the `downloader` function.\n",
    "\n",
    "16. Call `main` with `download_many` to test the script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading with concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flags_threadpool.py: threaded download script using futures.ThreadPoolExecutor\n",
    "\n",
    "from concurrent import futures\n",
    "\n",
    "def download_one(cc: str):#2\n",
    "    image = get_flag(cc)\n",
    "    save_flag(image, f'{cc}.gif')\n",
    "    print(cc, end=' ', flush=True)\n",
    "    return cc\n",
    "\n",
    "def download_many(cc_list: list[str]) -> int:\n",
    "    with futures.ThreadPoolExecutor() as executor: #3\n",
    "        res = executor.map(download_one, sorted(cc_list)) #4\n",
    "    return len(list(res)) #5\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reuse some functions from the `flags` module. (No need in jupyter notebook)\n",
    "\n",
    "2. Function to download a single image, this is what each worker will execute.\n",
    "\n",
    "3. Instantiate a `ThreadPoolExecutor` as a context manager; the `executor.__exit__` method will call `executor.shutdown(wait=True)`, which will block until all threads are done.\n",
    "\n",
    "4. The `map` method is similar to the `map` built-in, except the `download_one` function will be called concurrently from multiple threads; it returns a generator that you can iterate to retrieve the value returned by each function call--in this case, each call to `download_one` will return a country code.\n",
    "\n",
    "5. Return the number of results obtained. If any of the threaded calls raises an exception, that exception is raised here when the implicit `next()` call inside the `list` constructor tries to retrieve the corresponding value from the generator.\n",
    "\n",
    "6. Call the main function from the `flags` module, passing the concurrent version of `download_many`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first and most important argument of the `ThreadPoolExecutor` is `max_workers`, setting the maximum number of worker threads to executed. When `max_workers` is `None` or not given, its value using the following expression--since Python 3.8:\n",
    "\n",
    "```python\n",
    "max_workers = min(32, os.cpu_count() + 4)\n",
    "```\n",
    "\n",
    "> This default value preserves at least 5 threads for I/O bound tasks. It utilizes at most 32 CPU cores for CPU bound tasks which release the GIL. It avoids using very large resources implicitly on many-core machines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where Are the Futures?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Futures are core components of `concurrent.futures` and of `asyncio`. Since Python 3.4, there are `concurrent.futures.Future` and `asyncio.Future`. They server the same purpose: to represent a deferred computation that may or may not have completed yet. The difference is that `concurrent.futures.Future` is designed to be used with `concurrent.futures.Executor` objects, while `asyncio.Future` is intended for use with `asyncio` event loops.\n",
    "\n",
    "You should not create them: they are meant to be instantiated exclusively by the concurrency framework. Here is why: a `Future` represents something that will eventually run, therefore it must be scheduled to run, and that's the job of the framework. For example, the `Executor.submit()` method takes a callable, schedules it to run, and returns a `Future`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Futures and threads serve different purposes, even though they both involve representing deferred computations.\n",
    "\n",
    "1. Conceptual Difference:\n",
    "   - Futures: Futures are high-level abstractions that represent the result of an asynchronous operation or a task that may not have completed yet. They allow you to work with the result of an asynchronous computation when it becomes available.\n",
    "   - Threads: Threads, on the other hand, are lower-level constructs that represent a separate flow of execution within a process. They enable concurrent execution of multiple tasks or operations.\n",
    "\n",
    "2. Concurrency vs. Asynchrony:\n",
    "   - Futures: Futures are primarily used for asynchronous programming, where you can initiate multiple tasks concurrently and continue with other operations while waiting for the results. Futures provide a way to synchronize and retrieve the results of these asynchronous tasks.\n",
    "   - Threads: Threads, on the other hand, enable concurrent execution by allowing multiple threads of execution to run simultaneously. They are typically used for parallelism or when you have computationally intensive tasks that can benefit from running concurrently on multiple CPU cores.\n",
    "\n",
    "3. Resource Consumption:\n",
    "   - Futures: Working with futures generally involves less resource consumption compared to threads. Futures are typically lightweight and can be managed more efficiently, making them suitable for handling a large number of concurrent tasks without consuming excessive system resources.\n",
    "   - Threads: Threads, being lower-level constructs, tend to consume more system resources, such as memory and CPU time. Creating and managing threads can have overhead, and having too many threads can lead to decreased performance or even resource exhaustion.\n",
    "\n",
    "In summary, futures and threads have different purposes and use cases. Futures are designed for managing asynchronous computations and retrieving results, while threads enable concurrent execution of multiple tasks. Understanding these differences can help you choose the appropriate approach based on your specific requirements and constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduled for BR: <Future at 0x1ff9009bc80 state=running>\n",
      "Scheduled for CN: <Future at 0x1ff9009ad50 state=running>\n",
      "Scheduled for ID: <Future at 0x1ff9118e3f0 state=running>\n",
      "Scheduled for IN: <Future at 0x1ff91216630 state=pending>\n",
      "Scheduled for US: <Future at 0x1ff91215a30 state=pending>\n",
      "ID ThreadPoolExecutor-6_2 <Future at 0x1ff9118e3f0 state=finished returned str> result: 'ID'\n",
      "CN ThreadPoolExecutor-6_1 <Future at 0x1ff9009ad50 state=finished returned str> result: 'CN'\n",
      "BR ThreadPoolExecutor-6_0 <Future at 0x1ff9009bc80 state=finished returned str> result: 'BR'\n",
      "IN ThreadPoolExecutor-6_2 <Future at 0x1ff91216630 state=finished returned str> result: 'IN'\n",
      "US ThreadPoolExecutor-6_1 <Future at 0x1ff91215a30 state=finished returned str> result: 'US'\n",
      "\n",
      "5 downloads in 7.69s\n"
     ]
    }
   ],
   "source": [
    "# flags_threadpool_futures.py: replacing `executor.map` with `executor.submit` \n",
    "# and `futures.as_completed` in the `download_many` function\n",
    "\n",
    "def download_many(cc_list: list[str]) -> int:\n",
    "    cc_list = cc_list[:5] #1\n",
    "    with futures.ThreadPoolExecutor(max_workers=3) as executor: #2\n",
    "        to_do: list[futures.Future] = []\n",
    "        for cc in sorted(cc_list): #3\n",
    "            future = executor.submit(download_one, cc) #4\n",
    "            to_do.append(future) #5\n",
    "            print(f'Scheduled for {cc}: {future}') #6            \n",
    "\n",
    "        for count, future in enumerate(futures.as_completed(to_do), 1): #7\n",
    "            res: str = future.result() #8\n",
    "            print(f'{future} result: {res!r}') #9\n",
    "    \n",
    "    return count\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For this demonstration, use only the top five most populous countries.\n",
    "\n",
    "2. Set `max_workers` to 3, so we can see pending futures in the output.\n",
    "\n",
    "3. Iterate over country codes alphabetically, to make it clear that results will arrive out of order. And the output will be possible different every time you run the script.\n",
    "\n",
    "4. `executor.submit` schedules the callable to be executed, and returns a `future` representing this pending operation.\n",
    "\n",
    "5. Store each `future` so we can later retrieve them `as_completed`.\n",
    "\n",
    "6. Display a message with the country code and the respective `future` object.\n",
    "\n",
    "7. `as_completed` yields futures as they are completed.\n",
    "\n",
    "8. Get the result of this future.\n",
    "\n",
    "9. Display the future and this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "Scheduled for BR: <Future at 0x25fc79380e0 state=running> #1\n",
    "Scheduled for CN: <Future at 0x25fc86f8470 state=running>\n",
    "Scheduled for ID: <Future at 0x25fc76f6c60 state=running>\n",
    "Scheduled for IN: <Future at 0x25fc7958410 state=pending> #2\n",
    "Scheduled for US: <Future at 0x25fc7958fe0 state=pending>\n",
    "CN <Future at 0x25fc86f8470 state=finished returned str> result: 'CN' #3\n",
    "ID BR <Future at 0x25fc76f6c60 state=finished returned str> result: 'ID' #4\n",
    "<Future at 0x25fc79380e0 state=finished returned str> result: 'BR'\n",
    "IN <Future at 0x25fc7958410 state=finished returned str> result: 'IN'\n",
    "US <Future at 0x25fc7958fe0 state=finished returned str> result: 'US'\n",
    "```\n",
    "\n",
    "1. The futures are scheduled in alphabetical order; the repr() of a future shows its\n",
    "state: the first three are running , because there are three worker threads.\n",
    "\n",
    "2. The last two futures are pending , waiting for worker threads.\n",
    "\n",
    "3. The first CN here is the output of download_one in a worker thread; the rest of the\n",
    "line is the output of download_many \n",
    "\n",
    "4. Here, two threads output codes before download_many in the main thread can\n",
    "display the result of the first thread.\n",
    "\n",
    "How can I print thread info here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduled for BR: <Future at 0x272435a5ff0 state=running>\n",
      "Scheduled for CN: <Future at 0x2724355e5f0 state=running>\n",
      "Scheduled for ID: <Future at 0x272465a3820 state=running>\n",
      "Scheduled for IN: <Future at 0x272465dbb80 state=pending>\n",
      "Scheduled for US: <Future at 0x272465dbb50 state=pending>\n",
      "ID ThreadPoolExecutor-0_2 <Future at 0x272465a3820 state=finished returned str> result: 'ID'\n",
      "IN ThreadPoolExecutor-0_2 <Future at 0x272465dbb80 state=finished returned str> result: 'IN'\n",
      "CN ThreadPoolExecutor-0_1 <Future at 0x2724355e5f0 state=finished returned str> result: 'CN'\n",
      "US ThreadPoolExecutor-0_2 <Future at 0x272465dbb50 state=finished returned str> result: 'US'\n",
      "BR ThreadPoolExecutor-0_0 <Future at 0x272435a5ff0 state=finished returned str> result: 'BR'\n",
      "\n",
      "5 downloads in 2.90s\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from concurrent import futures\n",
    "\n",
    "def download_one(cc: str):\n",
    "    image = get_flag(cc)\n",
    "    save_flag(image, f'{cc}.gif')\n",
    "    print(cc, end=' ', flush=True)\n",
    "    print(threading.current_thread().name, end=' ', flush=True)\n",
    "    return cc\n",
    "\n",
    "def download_many(cc_list: list[str]) -> int:\n",
    "    cc_list = cc_list[:5]\n",
    "    with futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        to_do: list[futures.Future] = []\n",
    "        for cc in sorted(cc_list):\n",
    "            future = executor.submit(download_one, cc)\n",
    "            to_do.append(future)\n",
    "            print(f'Scheduled for {cc}: {future}')            \n",
    "        \n",
    "        count = 0\n",
    "        for count, future in enumerate(futures.as_completed(to_do), 1):  # Access thread name from tuple\n",
    "            res: str = future.result()\n",
    "            print(f'{future} result: {res!r}')\n",
    "    \n",
    "    return count\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching Process with `concurrent.futures`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`futures.ProcessPoolExecutor()` doesn't work in Jupyter Notebook.\n",
    "\n",
    "The `ProcessPoolExecutor` class is similar to `ThreadPoolExecutor`, but it uses processes instead of threads. The API is the same, but the underlying implementation is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from concurrent import futures #1\n",
    "from time import perf_counter\n",
    "from typing import NamedTuple\n",
    "\n",
    "from primes import is_prime, NUMBERS\n",
    "\n",
    "class PrimeResult(NamedTuple): #2\n",
    "    number: int\n",
    "    flag: bool\n",
    "    elapsed: float\n",
    "    \n",
    "def check(n: int) -> PrimeResult:\n",
    "    t0 = perf_counter()\n",
    "    res = is_prime(n)\n",
    "    elapsed = perf_counter() - t0\n",
    "    return PrimeResult(n, res, elapsed)\n",
    "\n",
    "def main(workers = None) -> None: #3\n",
    "    executor = futures.ProcessPoolExecutor(workers) #4\n",
    "    actual_workers = executor._max_workers #5\n",
    "    \n",
    "    print(f'Checking {len(NUMBERS)} numbers using {actual_workers} workers')\n",
    "    \n",
    "    t0 = perf_counter()\n",
    "    \n",
    "    numbers = sorted(NUMBERS)\n",
    "    with executor:\n",
    "        for number, prime, elapsed in executor.map(check, numbers):\n",
    "            label = 'P' if prime else ' '\n",
    "            print(f'{number:16}  {label} {elapsed:9.6f}s')\n",
    "    time = perf_counter() - t0\n",
    "    print(f'Total time: {time:.2f}s')\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. No need to import `multiprocessing, SimpleQueue` etc.; `concurrent.futures` takes care of that.\n",
    "\n",
    "2. The `PrimeResult` tuple and the `check` function are the same as we saw in `procs.py`, but we don't need queues and the `worker` function anymore.\n",
    "\n",
    "3. Instead of deciding ourselves how many workers to use if no-argument constructor is called, we set `workers` to `None` and let `ProcessPoolExecutor` decide.\n",
    "\n",
    "4. Here I build the `ProcessPoolExecutor` before the `with` block in 7, so that I can display the actual number of workers used.\n",
    "\n",
    "5. `_max_workers` is an undocumented instance attribute of `ProcessPoolExecutor` that holds the number of worker processes.\n",
    "\n",
    "6. Sort the numbers to be checked in descending order. This will expose a difference in the behavior of `proc_pool.py` when compared to `procs.py`.\n",
    "\n",
    "7. Use the `executor` as a context manager. The `executor.__exit__` method calls `executor.shutdown(wait=True)`, which will block until all processes are done.\n",
    "\n",
    "8. The `executor.map` call returns the `PrimeResult` instances returned by `check` in the same order as the `numbers` arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "Checking 20 numbers using 10 workers\n",
    "9999999999999999     0.000004s  #1\n",
    "9999999999999917  P  4.763032s  #2\n",
    "7777777777777777     0.000004s  #3\n",
    "7777777777777753  P  3.443294s\n",
    "7777777536340681     3.446641s\n",
    "6666667141414921     6.048437s\n",
    "6666666666666719  P  5.974608s\n",
    "6666666666666666     0.000001s\n",
    "5555555555555555     0.000004s\n",
    "5555555555555503  P  5.439129s\n",
    "5555553133149889     4.971766s\n",
    "4444444488888889     5.156169s\n",
    "4444444444444444     0.000001s\n",
    "4444444444444423  P  5.367763s\n",
    "3333335652092209     5.046108s\n",
    "3333333333333333     0.000005s\n",
    "3333333333333301  P  2.220393s\n",
    " 299593572317531  P  0.664979s\n",
    " 142702110479723  P  0.456387s\n",
    "               2  P  0.000001s\n",
    "Total time: 6.30s\n",
    "```\n",
    "\n",
    "1. This line appears very quickly.\n",
    "\n",
    "2. This line takes more than 4.6s to show up.\n",
    "\n",
    "3. All the remaining lines appear almost immediately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Executor.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:08:12] Script starting.\n",
      "[11:08:12] \t\t\t\t\tloiter(5):doing nothing for 5s\n",
      "[11:08:12] \t\t\t\tloiter(4):doing nothing for 4s\n",
      "[11:08:12] \t\t\tloiter(3):doing nothing for 3s\n",
      "[11:08:12] results: <generator object Executor.map.<locals>.result_iterator at 0x0000027246C8FA70>\n",
      "[11:08:12] Waiting for individual results:\n",
      "[11:08:15] \t\t\tloiter(3): done.\n",
      "[11:08:15] \t\tloiter(2):doing nothing for 2s\n",
      "[11:08:16] \t\t\t\tloiter(4): done.\n",
      "[11:08:16] \tloiter(1):doing nothing for 1s\n",
      "[11:08:17][11:08:17] \t\tloiter(2): done.\n",
      "[11:08:17] loiter(0):doing nothing for 0s\n",
      "[11:08:17] loiter(0): done.\n",
      " \t\t\t\t\tloiter(5): done.\n",
      "[11:08:17] result 0: 50\n",
      "[11:08:17] result 1: 40\n",
      "[11:08:17] result 2: 30\n",
      "[11:08:17] result 3: 20\n",
      "[11:08:17] \tloiter(1): done.\n",
      "[11:08:17] result 4: 10\n",
      "[11:08:17] result 5: 0\n"
     ]
    }
   ],
   "source": [
    "# Example 20-8. demo_executor_map.py: Simple demonstration\n",
    "# of the ThreadPoolExecutor\n",
    "from time import sleep, strftime\n",
    "from concurrent import futures\n",
    "\n",
    "def display(*args): #1\n",
    "    print(strftime('[%H:%M:%S]'), end=' ')\n",
    "    print(*args)\n",
    "    \n",
    "    \n",
    "def loiter(n): #2\n",
    "    msg = '{}loiter({}):doing nothing for {}s'\n",
    "    display(msg.format('\\t'*n, n, n))\n",
    "    sleep(n)\n",
    "    msg = '{}loiter({}): done.'\n",
    "    display(msg.format('\\t'*n, n))\n",
    "    return n * 10 #3\n",
    "    \n",
    "def main():\n",
    "    display('Script starting.')\n",
    "    executor = futures.ThreadPoolExecutor(max_workers=3) #4\n",
    "    results = executor.map(loiter, range(6)[::-1])    #5\n",
    "    display('results:', results)    #6\n",
    "    display('Waiting for individual results:')\n",
    "    for i, result in enumerate(results):    #7\n",
    "        display(f'result {i}: {result}')\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This function simply prints whatever arguments it gets, preceded by a timestamp in the format [HH:MM:SS].\n",
    "\n",
    "2. `loiter` does nothing except display a message when it starts, sleep for `n` seconds, then display a message when it ends; tabs are used to indent the messages according to the value of `n`.\n",
    "\n",
    "3. `loiter` returns `n * 10` so we can see how to collect results.\n",
    "\n",
    "4. Create a `ThreadPoolExecutor` with three threads.\n",
    "\n",
    "5. Submit five tasks to the `executor`. Since there are only there threads, only three of those tasks will start immediately: the calls `loiter(0)` , `loiter(1)` , and `loiter(2)` . The other two tasks will be queued.\n",
    "\n",
    "6. Immediately display the results of invoking `executor.map`: it's a generator, as the output shows.\n",
    "\n",
    "7. The `enumerate` call in the `for` loop will implicitly invoke `next(results)`, which in turn will invoke `_f.result()` on the (internal) _f future representing the first `call`, `loiter(0)`. The `result` method will block until the future is done, therefore each iteration in this loop will have to wait for the next result to be ready."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
